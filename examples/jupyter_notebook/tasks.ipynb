{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "895f3c55",
      "metadata": {
        "id": "895f3c55"
      },
      "source": [
        "# About this Notebook\n",
        "\n",
        "This is a tutorial file for interactively showing how to use flowcean. In this Jupyter notebook, you will go through the steps of training machine learning models using the [`flowcean`](https://flowcean.me/) framework. If you want to code along, use this notebook and see the solutions underneath each task. We also provide [all the solutions combined in one notebook](solutions.ipynb).\n",
        "\n",
        "This example is created using the package [turtlesim](http://wiki.ros.org/turtlesim), a tool designed for teaching the Robot Operating System (ROS). The example trains models to predict the next pose of the turtle, $\\textbf{x}_{k+1}$, based on the current pose $\\textbf{x}_{k}$ and velocity commands $\\textbf{u}_{k}$.\n",
        "\n",
        "ROS uses _topics_ to communicate between _nodes_. Nodes are processes that perform computations. They can **subscribe** to topics (receive messages from other nodes) or **publish** on topics (send messages to other nodes). In this example, the velocity commands are published to the `/turtle1/cmd_vel` topic by the turtle's teleop node (a node that lets you control the turtle interactively). The turtlesim node receives these velocity commands by subscribing to `/turtle1/cmd_vel` and publishes the turtle's pose to `/turtle1/pose`.\n",
        "\n",
        "![Motion model for turtlesim](images/turtlesim_model.svg)\n",
        "\n",
        "You can record ROS bag files using the _rosbag_ command-line tool. A ROS bag is a file format for storing ROS message data. It is commonly used for logging data during robot operation, which can later be played back for analysis or testing.\n",
        "The tutorial uses ROS bag data recorded from turtlesim, processes it into supervised samples, trains multiple models, evaluates them using several metrics, and plots predictions versus ground truth.\n",
        "\n",
        "![Turtlesim simulation](images/turtlesim.png)\n",
        "\n",
        "**Topics used:**\n",
        "\n",
        "- `/turtle1/cmd_vel` with fields `linear.x`, `angular.z`  \n",
        "- `/turtle1/pose` with fields `x`, `y`, `theta`  \n",
        "\n",
        "`/turtle1/cmd_vel` specifies the desired linear and angular velocities for the turtle. `/turtle1/pose` provides the turtle's actual position and orientation in the simulation environment.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "u08do7ih1GeN",
      "metadata": {
        "id": "u08do7ih1GeN"
      },
      "source": [
        "## Section 0: Experiment Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e7a75a6",
      "metadata": {
        "id": "3e7a75a6"
      },
      "outputs": [],
      "source": [
        "import flowcean.cli\n",
        "\n",
        "# The function below looks for a config.yaml in the current directory.\n",
        "# In the config.yaml, you can specify settings for the training run\n",
        "config = flowcean.cli.initialize()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e03844bf",
      "metadata": {
        "id": "e03844bf"
      },
      "source": [
        "## Section 1 : Load and Prepare the Training Data\n",
        "You will use the turtlesim example dataset for this tutorial. The dataset is a ROS 2 bag file that contains the pose and velocity of a turtle in the turtlesim simulator. The goal is to predict the next pose of the turtle given its current pose and velocity.\n",
        "\n",
        "A config file specifies paths and parameters for the training run. This allows you to easily modify the training setup without changing the code and improves reproducibility. The contents of the config file can then be accessed in the code as a dictionary.  \n",
        "See `config.yaml` for details of the configuration used in this workshop.  \n",
        "\n",
        "The example expects two ROS bag directories in the config:\n",
        "\n",
        "- Training: `rosbag.training_path`  \n",
        "- Evaluation: `rosbag.evaluation_path`  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "842384e0",
      "metadata": {
        "id": "842384e0"
      },
      "source": [
        "\n",
        "### Task 1.1 Load Rosbags and Choose Inputs\n",
        "\n",
        "First, you need to load the ROS 2 bag file and extract the relevant topics and fields. You will use the `from_rosbag` method of the `DataFrame` environment class.\n",
        "\n",
        "The topics and fields to be used are specified as a dictionary of lists. For this example, use the following topics and fields:   \n",
        "```yaml  \n",
        "  - /turtle1/cmd_vel\n",
        "      - linear.x\n",
        "      - angular.z\n",
        "  - /turtle1/pose\n",
        "      - x\n",
        "      - y\n",
        "      - theta\n",
        "```\n",
        "\n",
        "**Instructions**\n",
        "\n",
        "Specify the topics and their fields as a dictionary of lists."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62ea77fb",
      "metadata": {
        "id": "62ea77fb",
        "tags": [
          "hide-cell"
        ]
      },
      "outputs": [],
      "source": [
        "from flowcean.polars import DataFrame\n",
        "\n",
        "topics = {\n",
        "    # TODO: Task 1.1\n",
        "}\n",
        "\n",
        "# show current data structure without transforms\n",
        "rosbag_train = DataFrame.from_rosbag(config.rosbag.training_path, topics=topics)\n",
        "rosbag_eval = DataFrame.from_rosbag(config.rosbag.evaluation_path, topics=topics)\n",
        "print(rosbag_train.observe().collect())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f60ecbf8",
      "metadata": {
        "id": "f60ecbf8"
      },
      "source": [
        "<details>\n",
        "  <summary>ðŸ’¡ Click to see the solution</summary>\n",
        "\n",
        "```python\n",
        "topics = {\n",
        "    \"/turtle1/cmd_vel\": [\n",
        "        \"linear.x\",\n",
        "        \"angular.z\",\n",
        "    ],\n",
        "    \"/turtle1/pose\": [\n",
        "        \"x\",\n",
        "        \"y\",\n",
        "        \"theta\",\n",
        "    ],\n",
        "}\n",
        "```\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6c08d81",
      "metadata": {
        "id": "e6c08d81"
      },
      "source": [
        "Note that the current data structure is nested, has only one line, and is not yet suitable for training. This will be addressed in the next tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e07f8a7e",
      "metadata": {
        "id": "e07f8a7e"
      },
      "source": [
        "\n",
        "### Task 1.2 Create Training Data Frame\n",
        "\n",
        "Now that you have loaded the ROS 2 bag file, you need to create tabular training data that contains the input features and the target features. The input features are the current pose and velocity of the turtle, and the target feature is the next pose of the turtle.\n",
        "\n",
        "The following table shows how the values of the current pose vector $\\textbf{x}_{k}$ are shifted to form the next pose vector $\\textbf{x}_{k+1}$. The next pose vector is the supervised target you want to predict.\n",
        "\n",
        "| current pose $ \\textbf{x}_{k} $ | velocity command $ \\textbf{u}_{k} $     | next pose $ \\textbf{x}_{k+1} $   |\n",
        "|----------------------|----------------------|----------------------  |\n",
        "| [0, 0, 0]            | [1, 0]               | <span style=\"color:red\">[5, 0, 0]</span>            |\n",
        "| <span style=\"color:red\">[5, 0, 0]</span>          | [0, 1]               | <span style=\"color:green\">[5, 0, 2]</span>          |\n",
        "| <span style=\"color:green\">[5, 0, 2]</span>       | [5, 0]               | [7, 4, 2]            |\n",
        "| ...                    | ...                | ...                    |\n",
        "| [4, 2, 2]     | [0, 0]                | null                    |\n",
        "\n",
        "Note that this results in a null value for the next pose vector in the last row, which is filtered out.\n",
        "You will use the `ZeroOrderHold`, `ExplodeTimeSeries`, and `ShiftInTime` transforms from the `flowcean.polars` module to create the training data frame.\n",
        "You can concatenate/chain transforms to a dataframe with the `|` operator.\n",
        "\n",
        "**Instructions**\n",
        "\n",
        "Modify the `transforms` variable to create a chain of transforms with the following steps:\n",
        "- Call the `ZeroOrderHold` Transform:\n",
        "  - Our features are our topics\n",
        "  - Name the new column **\"measurements\"**\n",
        "\n",
        "- Use the `|` operator to chain the `ExplodeTimeSeries` Transform: \n",
        "  - Apply the `ExplodeTimeSeries` transform to the **\"measurements\"** column\n",
        "\n",
        "- Again, use the `|` operator to chain the `ShiftInTime` Transform:\n",
        "  - Apply the `ShiftInTime` transform to the **\"measurements\"** column\n",
        "  - Shift the features `/turtle1/pose/x`, `/turtle1/pose/y`, `/turtle1/pose/theta` \n",
        "  - Shift by **1 step** and give the new columns the suffix **\"_next\"**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ad11fe9",
      "metadata": {
        "id": "2ad11fe9"
      },
      "outputs": [],
      "source": [
        "from _helper_functions import ShiftInTime\n",
        "from flowcean.polars import ExplodeTimeSeries, ZeroOrderHold\n",
        "\n",
        "\n",
        "transforms = (\n",
        "    ZeroOrderHold(\n",
        "        # TODO: Task 1.2\n",
        "    ) \n",
        "    | ExplodeTimeSeries(\n",
        "        # TODO: Task 1.2\n",
        "    ) \n",
        "    | ShiftInTime(\n",
        "        # TODO: Task 1.2\n",
        "    )\n",
        ")\n",
        "\n",
        "# Show the transformed data structure\n",
        "training_environment = rosbag_train | transforms\n",
        "evaluation_environment = rosbag_eval | transforms\n",
        "print(training_environment.observe().collect())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5103304",
      "metadata": {
        "id": "b5103304"
      },
      "source": [
        "<details>\n",
        "  <summary>ðŸ’¡ Click to see the solution</summary>\n",
        "\n",
        "```python\n",
        "transforms = (\n",
        "    ZeroOrderHold(\n",
        "        features=[\n",
        "            \"/turtle1/cmd_vel\",\n",
        "            \"/turtle1/pose\",\n",
        "        ],\n",
        "        name=\"measurements\",\n",
        "    )\n",
        "    | ExplodeTimeSeries(\"measurements\")\n",
        "    | ShiftInTime(\n",
        "        features=[\"/turtle1/pose/x\", \"/turtle1/pose/y\", \"/turtle1/pose/theta\"],\n",
        "        steps=1,\n",
        "        suffix=\"_next\",\n",
        "    )\n",
        ")\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96b8eb94",
      "metadata": {
        "id": "96b8eb94"
      },
      "source": [
        "Now you have tabular data with aligned timestamps and separate columns for each feature."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53475c82",
      "metadata": {
        "id": "53475c82"
      },
      "source": [
        "## Section 2 : Select Learners across Libraries\n",
        "\n",
        "Now that you have your training and evaluation samples, you can select learners from different libraries. You will use a `RandomForestRegressor` and a `RegressionTree` from sklearn, a `MultilayerPerceptron` from PyTorch, and an `XGBoostRegressor` from XGBoost."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f796dd04",
      "metadata": {
        "id": "f796dd04"
      },
      "outputs": [],
      "source": [
        "inputs = [\n",
        "    \"/turtle1/pose/x\",\n",
        "    \"/turtle1/pose/y\",\n",
        "    \"/turtle1/pose/theta\",\n",
        "    \"/turtle1/cmd_vel/linear.x\",\n",
        "    \"/turtle1/cmd_vel/angular.z\",\n",
        "]\n",
        "outputs = [\n",
        "    \"/turtle1/pose/x_next\",\n",
        "    \"/turtle1/pose/y_next\",\n",
        "    \"/turtle1/pose/theta_next\",\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "334c2595",
      "metadata": {
        "id": "334c2595"
      },
      "source": [
        "\n",
        "### Task 2.1 Learner configuration\n",
        "Use the configurations defined in the `config.yaml` file to initialize our learners. The configurations are stored in the `config.learners` attribute.\n",
        "\n",
        "**Instructions**\n",
        "\n",
        "Initialize a regression tree, a random forest, a multilayer perceptron, and a XGBoost learner:\n",
        "   - pass the tree configuration to the regression tree\n",
        "   - pass the forest configuration to the random forest\n",
        "   - pass a multilayer perceptron instance to the lightning learner and pass both their respective configurations\n",
        "   - the XGBoost learner does not need to be configured\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89c18a95",
      "metadata": {
        "id": "89c18a95"
      },
      "outputs": [],
      "source": [
        "from flowcean.sklearn import RandomForestRegressorLearner, RegressionTree\n",
        "from flowcean.torch import LightningLearner, MultilayerPerceptron\n",
        "from flowcean.xgboost import XGBoostRegressorLearner\n",
        "\n",
        "regression_tree = RegressionTree(\n",
        "    max_leaf_nodes=None # TODO: Task 2.1\n",
        ")\n",
        "\n",
        "random_forest = RandomForestRegressorLearner(\n",
        "    n_estimators=None,  # TODO: Task 2.1\n",
        "    max_depth=None,  # TODO: Task 2.1\n",
        ")\n",
        "mlp = LightningLearner(\n",
        "    module=MultilayerPerceptron(\n",
        "        learning_rate=None,  # TODO: Task 2.1\n",
        "        output_size=len(outputs),\n",
        "    ),\n",
        "    batch_size=None,  # TODO: Task 2.1\n",
        "    max_epochs=None,  # TODO: Task 2.1\n",
        ")\n",
        "\n",
        "xgb = XGBoostRegressorLearner() # no parameters to pass here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d60be425",
      "metadata": {
        "id": "d60be425"
      },
      "source": [
        "<details>\n",
        "  <summary>ðŸ’¡ Click to see the solution</summary>\n",
        "\n",
        "```python\n",
        "regression_tree = RegressionTree(max_leaf_nodes=config.training.tree.max_leaf_nodes)\n",
        "\n",
        "random_forest = RandomForestRegressorLearner(\n",
        "    n_estimators=config.training.forest.n_estimators,\n",
        "    max_depth=config.training.forest.max_depth,\n",
        ")\n",
        "\n",
        "mlp = LightningLearner(\n",
        "    module=MultilayerPerceptron(\n",
        "        learning_rate=config.training.mlp.learning_rate,\n",
        "        output_size=len(outputs),\n",
        "    ),\n",
        "    batch_size=config.training.mlp.batch_size,\n",
        "    max_epochs=config.training.mlp.max_epochs,\n",
        ")\n",
        "\n",
        "xgb = XGBoostRegressorLearner()\n",
        "```\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce57354b",
      "metadata": {
        "id": "ce57354b"
      },
      "source": [
        "### Task 2.2 Prepare Sequential Learning\n",
        "The models should be learned in a looped fashion. To do this, you need to create a list of our learners.\n",
        "\n",
        "**Instructions**\n",
        "\n",
        "   - Create list for the learners"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c6639e8",
      "metadata": {
        "id": "9c6639e8"
      },
      "outputs": [],
      "source": [
        "learners = [\n",
        "    # TODO: Task 2.2\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88a204f6",
      "metadata": {
        "id": "88a204f6"
      },
      "source": [
        "<details>\n",
        "  <summary>ðŸ’¡ Click to see the solution</summary>\n",
        "\n",
        "```python\n",
        "learners = [\n",
        "    regression_tree,\n",
        "    random_forest,\n",
        "    mlp,\n",
        "    xgb,\n",
        "]\n",
        "```\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82cf79f6",
      "metadata": {
        "id": "82cf79f6"
      },
      "source": [
        "## Section 3: Training of the Models\n",
        "\n",
        "You will now train our models by looping over the learners list you created in the previous section and apply the `learn_offline` strategy."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe91dd18",
      "metadata": {
        "id": "fe91dd18"
      },
      "source": [
        "\n",
        "\n",
        "### Task 3.1 Create a Sequential Learning Loop\n",
        "\n",
        "you will now create a training loop that will train each learner on the training samples. you will store the trained models in a list.\n",
        "\n",
        "**Instructions**\n",
        "\n",
        "Implement the training loop:\n",
        "  - call the `learn_offline` function and pass the required parameters\n",
        "  - append the trained model to the models list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fe0ed37",
      "metadata": {
        "id": "8fe0ed37"
      },
      "outputs": [],
      "source": [
        "from flowcean.core import learn_offline\n",
        "\n",
        "models = []\n",
        "for learner in learners:\n",
        "    print(f\"Training model: {learner.name}\")\n",
        "\n",
        "    model = learn_offline # TODO: Task 2.2\n",
        "    models.append(model)\n",
        "\n",
        "print(models)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9191cfe",
      "metadata": {
        "id": "c9191cfe"
      },
      "source": [
        "\n",
        "<details>\n",
        "  <summary>ðŸ’¡ Click to see the solution</summary>\n",
        "\n",
        "  ```python\n",
        "models = []\n",
        "for learner in learners:\n",
        "    print(f\"Training model: {learner.name}\")\n",
        "    model = learn_offline(\n",
        "        training_environment,\n",
        "        learner,\n",
        "        inputs=inputs,\n",
        "        outputs=outputs,\n",
        "    )\n",
        "    models.append(model)\n",
        "\n",
        "  ```\n",
        "  \n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5594a375",
      "metadata": {
        "id": "5594a375"
      },
      "source": [
        "## Section 4 : Evaluation and Model Comparison\n",
        "\n",
        "Now, evaluate our trained models on the data of the evaluation environment. Use the `evaluate_offline` function from the `flowcean.training` to get an evaluation report for all the models which is printed in a tabular format."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35e812e4",
      "metadata": {
        "id": "35e812e4"
      },
      "source": [
        "### Task 4.1 Chose Metrics for Evaluation\n",
        "\n",
        "Evaluate the models using different metrics. Define a list of metrics that you want to use for evaluation. Use the following metrics:\n",
        "- Mean Absolute Error\n",
        "- Mean Squared Error\n",
        "- Regression Score (R2Score)\n",
        "- Mean Euclidean Distance\n",
        "\n",
        "**Instructions**   \n",
        "Define a list of metrics that you want to use for evaluation and add the required metrics to a list\n",
        "\n",
        "Note: The euclidean distance requires the features/columns it should be calculated on (`/turtle1/pose/x_next`, `/turtle1/pose/y_next`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07980f90",
      "metadata": {
        "id": "07980f90"
      },
      "outputs": [],
      "source": [
        "from euclidean_distance import MeanEuclideanDistance\n",
        "from flowcean.sklearn import MeanAbsoluteError, MeanSquaredError, R2Score\n",
        "\n",
        "metrics = [\n",
        "    # TODO: 4.1\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1a53e30",
      "metadata": {
        "id": "d1a53e30"
      },
      "source": [
        "<details>\n",
        "  <summary>ðŸ’¡ Click to see the solution</summary>\n",
        "\n",
        "```python\n",
        "metrics = [\n",
        "    MeanAbsoluteError(),\n",
        "    MeanSquaredError(),\n",
        "    R2Score(),\n",
        "    MeanEuclideanDistance(\n",
        "        features=[\"/turtle1/pose/x_next\", \"/turtle1/pose/y_next\"],\n",
        "    ),\n",
        "]\n",
        "```\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de636b99",
      "metadata": {
        "id": "de636b99"
      },
      "source": [
        "### Task 4.2 Create an Evaluation Loop\n",
        "\n",
        "Use the `evaluate_offline` strategy to evaluate each trained model on the evaluation samples. The resulting report object contains the results of all metrics for each model which can be displayed in a table using the `great_table()` method.\n",
        "\n",
        "**Instructions**\n",
        "\n",
        "Implement the evaluation loop:\n",
        "   - call the `evaluate_offline` function and pass the required parameters\n",
        "   - store the reports in a dict for later comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22e2f7eb",
      "metadata": {
        "id": "22e2f7eb"
      },
      "outputs": [],
      "source": [
        "from flowcean.core import evaluate_offline\n",
        "\n",
        "report = evaluate_offline(\n",
        "    # TODO: 4.2\n",
        ") \n",
        "report.great_table()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b2d3bd3",
      "metadata": {
        "id": "2b2d3bd3"
      },
      "source": [
        "<details>\n",
        "  <summary>ðŸ’¡ Click to see the solution</summary>\n",
        "\n",
        "```python\n",
        "report = evaluate_offline(\n",
        "    models,\n",
        "    environment=evaluation_environment,\n",
        "    metrics=metrics,\n",
        "    inputs=inputs,\n",
        "    outputs=outputs,\n",
        ")\n",
        "report.great_table()\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e674663",
      "metadata": {
        "id": "2e674663"
      },
      "source": [
        "\n",
        "###  Task 4.3 Select a Model and Visualization  \n",
        "\n",
        "Select the best model based on the evaluation reports you created in the previous task. You can visualize the predictions of the best model against the ground truth using the `predictions_vs_ground_truth` function from the same module.\n",
        "\n",
        " **Instructions**\n",
        "\n",
        "   - Choose the best model based on the evaluation report\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c18cea52",
      "metadata": {
        "id": "c18cea52"
      },
      "outputs": [],
      "source": [
        "from _helper_functions import plot_predictions_vs_ground_truth\n",
        "\n",
        "best_model = None  # TODO: 4.3\n",
        "print(f\"Best model: {best_model.name}\")\n",
        "\n",
        "# Plots are saved under plots/\n",
        "plot_predictions_vs_ground_truth(\n",
        "    environment=evaluation_environment,\n",
        "    input_names=inputs,\n",
        "    output_names=outputs,\n",
        "    models=models,\n",
        ")\n",
        "\n",
        "# save model to disk\n",
        "best_model.save(\"model.fml\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccdf6fc2",
      "metadata": {
        "id": "ccdf6fc2"
      },
      "source": [
        "<details>\n",
        "  <summary>ðŸ’¡ Click to see a solution</summary>\n",
        "  \n",
        "```python\n",
        "best_model = models[3]  # XGBoost model\n",
        "```\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3339547",
      "metadata": {},
      "source": [
        "Now you have successfully trained and evaluated multiple machine learning models using the Flowcean framework! You have selected the best model based on the evaluation metrics and visualized its predictions against the ground truth. The best model is exported and can be used for deployment in a ROS 2 environment using the [flowcean-ros](https://github.com/flowcean/flowcean-ros) package."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "flowcean (3.12.8)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
