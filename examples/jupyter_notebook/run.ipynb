{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "895f3c55",
      "metadata": {
        "id": "895f3c55"
      },
      "source": [
        "# About this Example\n",
        "\n",
        "This example demonstrates how to use Jupyter Notebooks to work with the Flowcean framework. \n",
        "\n",
        "![Turtlesim simulation](images/turtlesim.png)\n",
        "\n",
        "This example is created using the package [turtlesim](http://wiki.ros.org/turtlesim), a tool designed for teaching the Robot Operating System (ROS). The example trains models to predict the next pose of the turtle, $\\textbf{x}_{k+1}$, based on the current pose $\\textbf{x}_{k}$ and velocity commands $\\textbf{u}_{k}$.\n",
        "\n",
        "![Motion model for turtlesim](images/turtlesim_model.svg)\n",
        "\n",
        "ROS uses _topics_ to communicate between _nodes_. Nodes are processes that perform computations. They can **subscribe** to topics (receive messages from other nodes) or **publish** on topics (send messages to other nodes). In this example, the velocity commands are published to the `/turtle1/cmd_vel` topic by the turtle's teleop node (a node that lets you control the turtle interactively). The turtlesim node receives these velocity commands by subscribing to `/turtle1/cmd_vel` and publishes the turtle's pose to `/turtle1/pose`.\n",
        "\n",
        "You can record ROS bag files using the _rosbag_ command-line tool. A ROS bag is a file format for storing ROS message data. It is commonly used for logging data during robot operation, which can later be played back for analysis or testing.\n",
        "The tutorial uses ROS bag data recorded from turtlesim, processes it into supervised samples, trains multiple models, evaluates them using several metrics, and plots predictions versus ground truth.\n",
        "\n",
        "For more information, please refer to the Jupyter notebooks provided in the `examples/jupyter_notebook/` directory.\n",
        "\n",
        "**Topics used:**\n",
        "\n",
        "- `/turtle1/cmd_vel` with fields `linear.x`, `angular.z`  \n",
        "- `/turtle1/pose` with fields `x`, `y`, `theta`  \n",
        "\n",
        "`/turtle1/cmd_vel` specifies the desired linear and angular velocities for the turtle. `/turtle1/pose` provides the turtle's actual position and orientation in the simulation environment.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "u08do7ih1GeN",
      "metadata": {
        "id": "u08do7ih1GeN"
      },
      "source": [
        "## Section 0: Experiment Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e7a75a6",
      "metadata": {
        "id": "3e7a75a6"
      },
      "outputs": [],
      "source": [
        "import flowcean.cli\n",
        "\n",
        "# The function below looks for a config.yaml in the current directory.\n",
        "# In the config.yaml, we specify settings for our training run\n",
        "config = flowcean.cli.initialize()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e03844bf",
      "metadata": {
        "id": "e03844bf"
      },
      "source": [
        "## Section 1 : Load and Prepare the Training Data\n",
        "We will use the turtlesim example dataset for this tutorial. The dataset is a ROS 2 bag file that contains the pose and velocity of a turtle in the turtlesim simulator. The goal is to predict the next pose of the turtle given its current pose and velocity.\n",
        "\n",
        "A config file specifies paths and parameters for the training run. This allows you to easily modify the training setup without changing the code and improves reproducibility. The contents of the config file can then be accessed in the code as a dictionary.  \n",
        "See `config.yaml` for details of the configuration used in this workshop.  \n",
        "\n",
        "The example expects two ROS bag directories in the config:\n",
        "\n",
        "- Training: `rosbag.training_path`  \n",
        "- Evaluation: `rosbag.evaluation_path`  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "842384e0",
      "metadata": {
        "id": "842384e0"
      },
      "source": [
        "\n",
        "### Load Rosbags and Choose Inputs\n",
        "\n",
        "First, we need to load the ROS 2 bag file and extract the relevant topics and fields. We will use the `from_rosbag` method of the `DataFrame` environment class.\n",
        "\n",
        "The topics and fields we want to load are:   \n",
        "```yaml  \n",
        "  - /turtle1/cmd_vel\n",
        "      - linear.x\n",
        "      - angular.z\n",
        "  - /turtle1/pose\n",
        "      - x\n",
        "      - y\n",
        "      - theta\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62ea77fb",
      "metadata": {
        "id": "62ea77fb",
        "tags": [
          "hide-cell"
        ]
      },
      "outputs": [],
      "source": [
        "from flowcean.polars import DataFrame\n",
        "\n",
        "topics = {\n",
        "    \"/turtle1/cmd_vel\": [\"linear.x\", \"angular.z\"],\n",
        "    \"/turtle1/pose\": [\"x\", \"y\", \"theta\"],\n",
        "}\n",
        "# show current data structure without transforms\n",
        "rosbag_train = DataFrame.from_rosbag(config.rosbag.training_path, topics=topics)\n",
        "print(rosbag_train.observe().collect())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6c08d81",
      "metadata": {
        "id": "e6c08d81"
      },
      "source": [
        "Note that the current data structure is nested, has only one line, and is not yet suitable for training. We will address this in the next tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e07f8a7e",
      "metadata": {
        "id": "e07f8a7e"
      },
      "source": [
        "\n",
        "### Create Training Data Frame\n",
        "\n",
        "Now that we have loaded the ROS 2 bag file, we need to create tabular training data that contains the input features and the target features. The input features are the current pose and velocity of the turtle, and the target feature is the next pose of the turtle.\n",
        "\n",
        "The following table shows how the values of the current pose vector $\\textbf{x}_{k}$ are shifted to form the next pose vector $\\textbf{x}_{k+1}$. The next pose vector is the supervised target we want to predict.\n",
        "\n",
        "| current pose $ \\textbf{x}_{k} $ | velocity command $ \\textbf{u}_{k} $     | next pose $ \\textbf{x}_{k+1} $   |\n",
        "|----------------------|----------------------|----------------------  |\n",
        "| [0, 0, 0]            | [1, 0]               | <span style=\"color:red\">[5, 0, 0]</span>            |\n",
        "| <span style=\"color:red\">[5, 0, 0]</span>          | [0, 1]               | <span style=\"color:green\">[5, 0, 2]</span>          |\n",
        "| <span style=\"color:green\">[5, 0, 2]</span>       | [5, 0]               | [7, 4, 2]            |\n",
        "| ...                    | ...                | ...                    |\n",
        "| [4, 2, 2]     | [0, 0]                | null                    |\n",
        "\n",
        "Note that this results in a null value for the next pose vector in the last row, which is filtered out.\n",
        "We will use the `ZeroOrderHold`, `ExplodeTimeSeries`, and `ShiftInTime` transforms from the `flowcean.polars` module to create the training data frame.\n",
        "You can concatenate/chain transforms to a dataframe with the `|` operator.\n",
        "We modify the `transforms` variable to create a chain of transforms with the following steps:\n",
        "- Call the `ZeroOrderHold` Transform:\n",
        "  - Our features are our topics\n",
        "  - Name the new column **\"measurements\"**\n",
        "\n",
        "- Use the `|` operator to chain the `ExplodeTimeSeries` Transform: \n",
        "  - Apply the `ExplodeTimeSeries` transform to the **\"measurements\"** column\n",
        "\n",
        "- Again, use the `|` operator to chain the `ShiftInTime` Transform:\n",
        "  - Apply the `ShiftInTime` transform to the **\"measurements\"** column\n",
        "  - Shift the features `/turtle1/pose/x`, `/turtle1/pose/y`, `/turtle1/pose/theta` \n",
        "  - Shift by **1 step** and give the new columns the suffix **\"_next\"**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ad11fe9",
      "metadata": {
        "id": "2ad11fe9"
      },
      "outputs": [],
      "source": [
        "from _helper_functions import ShiftInTime\n",
        "from flowcean.polars import DataFrame, ExplodeTimeSeries, ZeroOrderHold\n",
        "\n",
        "transforms = (\n",
        "    ZeroOrderHold(\n",
        "        features=[\n",
        "            \"/turtle1/cmd_vel\",\n",
        "            \"/turtle1/pose\",\n",
        "        ],\n",
        "        name=\"measurements\",\n",
        "    )\n",
        "    | ExplodeTimeSeries(\"measurements\")\n",
        "    | ShiftInTime(\n",
        "        features=[\"/turtle1/pose/x\", \"/turtle1/pose/y\", \"/turtle1/pose/theta\"],\n",
        "        steps=1,\n",
        "        suffix=\"_next\",\n",
        "    )\n",
        ")\n",
        "\n",
        "training_environment = (\n",
        "    DataFrame.from_rosbag(config.rosbag.training_path, topics=topics) | transforms\n",
        ")\n",
        "evaluation_environment = (\n",
        "    DataFrame.from_rosbag(config.rosbag.evaluation_path, topics=topics) | transforms\n",
        ")\n",
        "print(training_environment.observe().collect())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96b8eb94",
      "metadata": {
        "id": "96b8eb94"
      },
      "source": [
        "Now we have tabular data with aligned timestamps and separate columns for each feature."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53475c82",
      "metadata": {
        "id": "53475c82"
      },
      "source": [
        "## Section 2 : Select Learners across Libraries\n",
        "\n",
        "Now that we have our training and evaluation samples, we can select learners from different libraries. We will use a `RandomForestRegressor` and a `RegressionTree` from sklearn, a `MultilayerPerceptron` from PyTorch, and an `XGBoostRegressor` from XGBoost."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f796dd04",
      "metadata": {
        "id": "f796dd04"
      },
      "outputs": [],
      "source": [
        "inputs = [\n",
        "    \"/turtle1/pose/x\",\n",
        "    \"/turtle1/pose/y\",\n",
        "    \"/turtle1/pose/theta\",\n",
        "    \"/turtle1/cmd_vel/linear.x\",\n",
        "    \"/turtle1/cmd_vel/angular.z\",\n",
        "]\n",
        "outputs = [\n",
        "    \"/turtle1/pose/x_next\",\n",
        "    \"/turtle1/pose/y_next\",\n",
        "    \"/turtle1/pose/theta_next\",\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "334c2595",
      "metadata": {
        "id": "334c2595"
      },
      "source": [
        "\n",
        "### Task 2.1 Learner configuration\n",
        "We will use the configurations defined in the `config.yaml` file to initialize our learners. The configurations are stored in the `config.learners` attribute.\n",
        "\n",
        "We initialize a regression tree, a random forest, a multilayer perceptron, and a XGBoost learner:\n",
        "   - pass the tree configuration to the regression tree\n",
        "   - pass the forest configuration to the random forest\n",
        "   - pass a multilayer perceptron instance to the lightning learner and pass both their respective configurations\n",
        "   - the XGBoost learner does not need to be configured\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89c18a95",
      "metadata": {
        "id": "89c18a95"
      },
      "outputs": [],
      "source": [
        "from flowcean.sklearn import RandomForestRegressorLearner, RegressionTree\n",
        "from flowcean.torch import LightningLearner, MultilayerPerceptron\n",
        "from flowcean.xgboost import XGBoostRegressorLearner\n",
        "\n",
        "regression_tree = RegressionTree(max_leaf_nodes=config.training.tree.max_leaf_nodes)\n",
        "\n",
        "random_forest = RandomForestRegressorLearner(\n",
        "    n_estimators=config.training.forest.n_estimators,\n",
        "    max_depth=config.training.forest.max_depth,\n",
        ")\n",
        "\n",
        "mlp = LightningLearner(\n",
        "    module=MultilayerPerceptron(\n",
        "        learning_rate=config.training.mlp.learning_rate,\n",
        "        output_size=len(outputs),\n",
        "    ),\n",
        "    batch_size=config.training.mlp.batch_size,\n",
        "    max_epochs=config.training.mlp.max_epochs,\n",
        "    accelerator=\"cpu\",\n",
        ")\n",
        "\n",
        "xgb = XGBoostRegressorLearner() # no parameters to pass here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce57354b",
      "metadata": {
        "id": "ce57354b"
      },
      "source": [
        "### Prepare Sequential Learning\n",
        "We want to train all of our models in a looped fassion. To do this, we need to create a list of our learners.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c6639e8",
      "metadata": {
        "id": "9c6639e8"
      },
      "outputs": [],
      "source": [
        "learners = [\n",
        "    regression_tree,\n",
        "    random_forest,\n",
        "    mlp,\n",
        "    xgb,\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82cf79f6",
      "metadata": {
        "id": "82cf79f6"
      },
      "source": [
        "## Training of the Models\n",
        "\n",
        "We will now train our models by looping over the learners list we created in the previous section and apply the `learn_offline` strategy."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe91dd18",
      "metadata": {
        "id": "fe91dd18"
      },
      "source": [
        "\n",
        "\n",
        "### Create a Sequential Learning Loop\n",
        "\n",
        "We will now create a training loop that will train each learner on the training samples. We will store the trained models in a list.\n",
        "\n",
        "We implement the training loop by:\n",
        "  - calling the `learn_offline` function and pass the required parameters\n",
        "  - appending the trained model to the models list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fe0ed37",
      "metadata": {
        "id": "8fe0ed37"
      },
      "outputs": [],
      "source": [
        "from flowcean.core import learn_offline\n",
        "\n",
        "models = []\n",
        "for learner in learners:\n",
        "    print(f\"Training model: {learner.name}\")\n",
        "    model = learn_offline(\n",
        "        training_environment,\n",
        "        learner,\n",
        "        inputs=inputs,\n",
        "        outputs=outputs,\n",
        "    )\n",
        "    models.append(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5594a375",
      "metadata": {
        "id": "5594a375"
      },
      "source": [
        "## Evaluation and Model Comparison\n",
        "\n",
        "We will now evaluate our trained models on the data of the evaluation environment. We will use the `evaluate_offline` function from the `flowcean.training` to get an evaluation report for all the models which is printed in a tabular format."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35e812e4",
      "metadata": {
        "id": "35e812e4"
      },
      "source": [
        "### Choose Metrics for Evaluation\n",
        "\n",
        "We want to evaluate our models using different metrics. We will define a list of metrics that we want to use for evaluation. The metrics we want to use are:\n",
        "- Mean Absolute Error\n",
        "- Mean Squared Error\n",
        "- Regression Score (R2Score)\n",
        "- Mean Euclidean Distance\n",
        "\n",
        "Note: The euclidean distance requires the features/columns it should be calculated on (`/turtle1/pose/x_next`, `/turtle1/pose/y_next`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07980f90",
      "metadata": {
        "id": "07980f90"
      },
      "outputs": [],
      "source": [
        "from euclidean_distance import MeanEuclideanDistance\n",
        "from flowcean.sklearn import MeanAbsoluteError, MeanSquaredError, R2Score\n",
        "\n",
        "metrics = [\n",
        "    MeanAbsoluteError(),\n",
        "    MeanSquaredError(),\n",
        "    R2Score(),\n",
        "    MeanEuclideanDistance(\n",
        "        features=[\"/turtle1/pose/x_next\", \"/turtle1/pose/y_next\"],\n",
        "    ),\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de636b99",
      "metadata": {
        "id": "de636b99"
      },
      "source": [
        "### Create an Evaluation Loop\n",
        "\n",
        "We will use the `evaluate_offline` strategy to evaluate each trained model on the evaluation samples. The resulting report object contains the results of all metrics for each model which can be displayed in a table using the `great_table()` method.\n",
        "\n",
        "Note: the `great_table()` only works in Jupyter Notebooks. For Python scripts, you can use `report.pretty_print()` to print the report to the console.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22e2f7eb",
      "metadata": {
        "id": "22e2f7eb"
      },
      "outputs": [],
      "source": [
        "from flowcean.core import evaluate_offline\n",
        "\n",
        "report = evaluate_offline(\n",
        "    models,\n",
        "    environment=evaluation_environment,\n",
        "    metrics=metrics,\n",
        "    inputs=inputs,\n",
        "    outputs=outputs,\n",
        ")\n",
        "report.great_table()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e674663",
      "metadata": {
        "id": "2e674663"
      },
      "source": [
        "\n",
        "###  Select a Model and Visualization  \n",
        "\n",
        "We want to select the best model based on the evaluation reports we created in the previous task. We will also visualize the predictions of the best model against the ground truth using the `predictions_vs_ground_truth` function from the same module.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c18cea52",
      "metadata": {
        "id": "c18cea52"
      },
      "outputs": [],
      "source": [
        "from _helper_functions import plot_predictions_vs_ground_truth\n",
        "\n",
        "best_model = models[3] # the XGBoost model is the best one and 4th in the list\n",
        "print(f\"Best model: {best_model.name}\")\n",
        "\n",
        "# Plots are saved under plots/\n",
        "plot_predictions_vs_ground_truth(\n",
        "    environment=evaluation_environment,\n",
        "    input_names=inputs,\n",
        "    output_names=outputs,\n",
        "    models=models,\n",
        ")\n",
        "\n",
        "# save model to disk\n",
        "best_model.save(\"model.fml\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3339547",
      "metadata": {},
      "source": [
        "Now you have successfully trained and evaluated multiple machine learning models using the Flowcean framework! You have selected the best model based on the evaluation metrics and visualized its predictions against the ground truth. The best model is exported and can be used for deployment in a ROS 2 environment. "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "flowcean (3.12.8)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
