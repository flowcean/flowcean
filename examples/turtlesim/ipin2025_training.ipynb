{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "895f3c55",
   "metadata": {},
   "source": [
    "# IPIN 2025 Flowcean Workshop\n",
    "This is the tutorial file for the IPIN 2025 workshop. In this Jupyter notebook, we will go through the steps of training machine learning models with the\n",
    "Flowcean framework.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "919276d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some imports we will need\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03844bf",
   "metadata": {},
   "source": [
    "## Section 1 : Load and Prepare the Training Data\n",
    "We will use the turtlesim example dataset for this tutorial. The dataset is a ROS2 bag file that contains the pose and velocity of a turtle in the turtlesim simulator. The goal is to predict the next pose of the turtle given its current pose and velocity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7a75a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import flowcean and cli\n",
    "import flowcean\n",
    "import flowcean.cli\n",
    "\n",
    "# The function below looks for a config.yaml in the current directory\n",
    "# In the config.yaml, we specify settings for our training run \n",
    "config = flowcean.cli.initialize()\n",
    "\n",
    "# Import some helper functions for loading ROS data\n",
    "from os import PathLike\n",
    "from _collections_abc import Iterable\n",
    "from flowcean.ros import load_rosbag\n",
    "from _helper_functions import shift_in_time\n",
    "\n",
    "# import transforms\n",
    "from flowcean.polars import DataFrame, ExplodeTimeSeries, ZeroOrderHold\n",
    "from flowcean.core.transform import Lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842384e0",
   "metadata": {},
   "source": [
    "\n",
    "### Task 1.1 Load Rosbags and Choose Inputs\n",
    "\n",
    "First, we need to load the ROS2 bag file and extract the relevant topics and fields. We will use the `load_rosbag` function from the `flowcean.ros` module to do this.\n",
    "\n",
    "The topics and fields we use load are:   \n",
    "```yaml  \n",
    "  - /turtle1/cmd_vel\n",
    "      - linear.x\n",
    "      - angular.z\n",
    "  - /turtle1/pose\n",
    "      - x\n",
    "      - y\n",
    "      - theta\n",
    "```\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "Call the load_rosbag function and pass:    \n",
    "  - the bag_path                           \n",
    "  - requires topics and their fields       \n",
    "  - the message_path                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ea77fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-08 11:08:50,177 [__main__][INFO] Loading rosbag from: recordings/turtle_training\n",
      "2025-09-08 11:08:50,178 [flowcean.ros.rosbag][INFO] Loading data from cache...\n",
      "2025-09-08 11:08:50,178 [__main__][INFO] Loading rosbag from: recordings/turtle_evaluation\n",
      "2025-09-08 11:08:50,179 [flowcean.ros.rosbag][INFO] Loading data from cache...\n"
     ]
    }
   ],
   "source": [
    "# Configure the load_rosbag() function below\n",
    "def load_and_process_rosbag(\n",
    "    path: str | PathLike,\n",
    "    message_paths: Iterable[str | PathLike] | None = None,\n",
    ") -> DataFrame:\n",
    "    logger.info(\"Loading rosbag from: %s\", path)\n",
    "\n",
    "    rosbag = load_rosbag(\n",
    "        # TODO: TASK 1.1\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        DataFrame(rosbag) \n",
    "    )\n",
    "\n",
    "# using our loaded config we want to create training and evaluation samples\n",
    "samples_train = load_and_process_rosbag(\n",
    "    config.rosbag.training_path,\n",
    "    config.rosbag.message_paths,\n",
    ")\n",
    "samples_eval = load_and_process_rosbag(\n",
    "    config.rosbag.evaluation_path,\n",
    "    config.rosbag.message_paths,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60ecbf8",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>ðŸ’¡ Click to see the solution</summary>\n",
    "\n",
    "```python\n",
    "    rosbag = load_rosbag(\n",
    "        path=path,\n",
    "        topics={\n",
    "            \"/turtle1/cmd_vel\": [\n",
    "                \"linear.x\",\n",
    "                \"angular.z\",\n",
    "            ],\n",
    "            \"/turtle1/pose\": [\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"theta\",\n",
    "            ],\n",
    "        },\n",
    "        message_paths=message_paths,\n",
    "    )   \n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07f8a7e",
   "metadata": {},
   "source": [
    "\n",
    "### Task 1.2 Create Training Data Frame\n",
    "\n",
    "Now that we have loaded the ROS2 bag file, we need to create a training data frame that contains the input features and the target variable. The input features are the current pose and velocity of the turtle, and the target variable is the next pose of the turtle.\n",
    "We will use the `ZeroOrderHold`, `ExplodeTimeSeries`, and `Lambda` transforms from the `flowcean.polars` module to create the training data frame.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "Modify the `load_and_process_rosbag` function to create a training data frame with the following steps:\n",
    "- Call the `ZeroOrderHold` Transform:\n",
    "  - our features are our topics\n",
    "  - name the new column \"measurments\"\n",
    "\n",
    "- Chain the `ExplodeTimeSeries` Transform: Apply the `ExplodeTimeSeries` transform to the measurement column\n",
    "\n",
    "- Chain the `Lambda` Transform: pass the function `shift_in_time`, which is imported at the start of the cell\n",
    "\n",
    "<details>\n",
    "  <summary>ðŸ’¡ Click to see a hint</summary>\n",
    "\n",
    "You can concatenate/chain transforms to a dataframe with the `|` operator.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0115e205",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-08 11:10:20,429 [__main__][INFO] Loading rosbag from: recordings/turtle_training\n",
      "2025-09-08 11:10:20,430 [flowcean.ros.rosbag][INFO] Loading data from cache...\n",
      "2025-09-08 11:10:20,431 [__main__][INFO] Loading rosbag from: recordings/turtle_evaluation\n",
      "2025-09-08 11:10:20,431 [flowcean.ros.rosbag][INFO] Loading data from cache...\n"
     ]
    }
   ],
   "source": [
    "# Modify the return statement below to include the necessary transforms\n",
    "def load_and_process_rosbag(\n",
    "        path: str | PathLike,\n",
    "        message_paths: Iterable[str | PathLike] | None = None,\n",
    "    ) -> DataFrame:\n",
    "    logger.info(\"Loading rosbag from: %s\", path)\n",
    "\n",
    "    rosbag = load_rosbag(\n",
    "        path=path,\n",
    "        message_paths=message_paths,\n",
    "        topics={\n",
    "            \"/turtle1/cmd_vel\": [\n",
    "                \"linear.x\",\n",
    "                \"angular.z\",\n",
    "            ],\n",
    "            \"/turtle1/pose\": [\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"theta\",\n",
    "            ],\n",
    "        },\n",
    "    )\n",
    "    return (\n",
    "        DataFrame(rosbag) \n",
    "        # TODO: TASK 1.2\n",
    "    )   \n",
    "\n",
    "\n",
    "# using our loaded config we want to create training and evaluation samples\n",
    "samples_train = load_and_process_rosbag(\n",
    "    config.rosbag.training_path,\n",
    "    config.rosbag.message_paths,\n",
    ")\n",
    "samples_eval = load_and_process_rosbag(\n",
    "    config.rosbag.evaluation_path,\n",
    "    config.rosbag.message_paths,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5103304",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>ðŸ’¡ Click to see the solution</summary>\n",
    "\n",
    "```python\n",
    "    def load_and_process_rosbag(\n",
    "            path: str | PathLike,\n",
    "            message_paths: Iterable[str | PathLike] | None = None,\n",
    "        ) -> DataFrame:\n",
    "            logger.info(\"Loading rosbag from: %s\", path)\n",
    "\n",
    "            rosbag = load_rosbag(\n",
    "                path=path,\n",
    "                message_paths=message_paths,\n",
    "                topics={\n",
    "                    \"/turtle1/cmd_vel\": [\n",
    "                        \"linear.x\",\n",
    "                        \"angular.z\",\n",
    "                    ],\n",
    "                    \"/turtle1/pose\": [\n",
    "                        \"x\",\n",
    "                        \"y\",\n",
    "                        \"theta\",\n",
    "                    ],\n",
    "                },\n",
    "            )\n",
    "\n",
    "            return (\n",
    "                DataFrame(rosbag)\n",
    "                | ZeroOrderHold(\n",
    "                    features=[\n",
    "                        \"/turtle1/cmd_vel\",\n",
    "                        \"/turtle1/pose\",\n",
    "                    ],\n",
    "                    name=\"measurements\",\n",
    "                )\n",
    "                | ExplodeTimeSeries(\"measurements\")\n",
    "                | Lambda(shift_in_time)\n",
    "            )   \n",
    "```\n",
    "\n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53475c82",
   "metadata": {},
   "source": [
    "## Section 2 : Select Learners across Libraries \n",
    "\n",
    "Now that we have our training and evaluation samples, we can select learners from different libraries. We will use a `RandomForestRegressor` and a `RegressionTree` from sklearn and a `MultilayerPerceptron` from PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f796dd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we load all the learners for our training loop\n",
    "from flowcean.sklearn import RandomForestRegressorLearner, RegressionTree\n",
    "from flowcean.torch import LightningLearner, MultilayerPerceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334c2595",
   "metadata": {},
   "source": [
    "\n",
    "### Task 2.1 Learner configuration\n",
    "We will use the configurations defined in the `config.yaml` file to initialize our learners. The configurations are stored in the `config.learners` attribute.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "Initialize a regression tree, a random forest, and a Lightning Learner:\n",
    "   - pass the tree configuration to the regression tree\n",
    "   - pass the forest configuration to the random forest\n",
    "   - pass a multilayer perceptron instance to the lightning learner and pass both their respective configurations\n",
    "\n",
    "\n",
    "<details>\n",
    "  <summary>ðŸ’¡ Click to see a hint</summary>\n",
    "    HINT: We defined our configurations in the config.yaml file.                     \n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c18a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and configure the learners below\n",
    "regression_tree = None  # TODO: Task 2.1\n",
    "\n",
    "random_forest = None    # TODO: Task 2.1\n",
    "\n",
    "mlp = None              # TODO: Task 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60be425",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>ðŸ’¡ Click to see the solution</summary>\n",
    "\n",
    "```python\n",
    "regression_tree = RegressionTree(\n",
    "    **config.training.tree\n",
    ")\n",
    "\n",
    "random_forest = RandomForestRegressorLearner(\n",
    "    **config.training.forest,\n",
    ")\n",
    "\n",
    "mlp = LightningLearner(\n",
    "    module=MultilayerPerceptron(\n",
    "        learning_rate=config.training.mlp.learning_rate,\n",
    "    ),\n",
    "    batch_size=config.training.mlp.batch_size,\n",
    "    max_epochs=config.training.mlp.max_epochs,\n",
    ")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce57354b",
   "metadata": {},
   "source": [
    "### Task 2.2 Prepare Sequential Learning\n",
    "We want to train all of our models in a looped fassion. To do this, we need to create a dictionary that maps the name of the learner to the learner instance. We also need to create two lists that contain the input and output fields of the topic we want to predict.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "   - Create dictionary for the learners\n",
    "   - Create a list that contains all fields of a topic that are part of the input\n",
    "   - Create a list that contains all fields of a topic that are part of the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6639e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the dictionaries and lists below\n",
    "learners = {\n",
    "    # TODO: Task 2.2\n",
    "}\n",
    "\n",
    "inputs = [\n",
    "    # TODO: Task 2.2\n",
    "]\n",
    "\n",
    "outputs = [\n",
    "    # TODO: Task 2.2\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a204f6",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>ðŸ’¡ Click to see the solution</summary>\n",
    "\n",
    "```python\n",
    "learners = {\n",
    "    \"regression_tree\": regression_tree,\n",
    "    \"random_forest\": random_forest,\n",
    "    \"multilayer_perceptron\": mlp,\n",
    "}\n",
    "\n",
    "inputs = [\n",
    "    \"/turtle1/pose/x\",\n",
    "    \"/turtle1/pose/y\",\n",
    "    \"/turtle1/pose/theta\",\n",
    "    \"/turtle1/cmd_vel/linear.x\",\n",
    "    \"/turtle1/cmd_vel/angular.z\",\n",
    "]\n",
    "outputs = [\n",
    "    \"/turtle1/pose/x_next\",\n",
    "    \"/turtle1/pose/y_next\",\n",
    "    \"/turtle1/pose/theta_next\",\n",
    "]\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cf79f6",
   "metadata": {},
   "source": [
    "## Section 3: Training of the Models\n",
    "\n",
    "We will now train our models by looping over the learners dictionary we created in the previous section and apply the `learn_offline strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2d91c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we load our learning strategy\n",
    "from flowcean.core import learn_offline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe91dd18",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Task 3.1 Create a Sequential Learning Loop\n",
    "\n",
    "We will now create a training loop that will train each learner on the training samples. We will store the trained models in a dictionary.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "Implement the training loop:\n",
    "  - call the `learn_offline` function and pass the required parameters\n",
    "  - store the trained models in a dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe0ed37",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "for learner_name, learner in learners.items():\n",
    "    logger.info(\"Training model: %s\", learner_name)\n",
    "\n",
    "    model = None                # TODO: Task 3.1\n",
    "    models[learner_name] = None # TODO: Task 3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9191cfe",
   "metadata": {},
   "source": [
    "\n",
    "<details>\n",
    "  <summary>ðŸ’¡ Click to see the solution</summary>\n",
    "\n",
    "  ```python\n",
    "  models = {}\n",
    "  for learner_name, learner in learners.items():\n",
    "      logger.info(\"Training model: %s\", learner_name)\n",
    "      \n",
    "      model = learn_offline(\n",
    "          samples_train,\n",
    "          learner,\n",
    "          inputs=inputs,\n",
    "          outputs=outputs,\n",
    "      )\n",
    "      models[learner_name] = model\n",
    "  ```\n",
    "  \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5594a375",
   "metadata": {},
   "source": [
    "## Section 4 : Evaluation and Model Comparison\n",
    "\n",
    "We will now evaluate our trained models on the evaluation samples. We will use the `evaluate_offline` function from the `flowcean.training` module to do this. We will also compare the performance of the models using the `compare_models` function from the same module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834e231d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we load our metrics for comparison\n",
    "from flowcean.sklearn import MaxError, MeanAbsoluteError, MeanSquaredError, R2Score\n",
    "from custom_metrics.euclidean_distance import MeanEuclideanDistance\n",
    "\n",
    "# import functions for comparison and visualization\n",
    "from flowcean.core import evaluate_offline\n",
    "from flowcean.core.strategies.offline import print_report_table, select_best_model\n",
    "from _helper_functions import plot_predictions_vs_ground_truth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e812e4",
   "metadata": {},
   "source": [
    "### Task 4.1 Chose Metrics for Evaluation\n",
    "\n",
    "We want to evaluate our models using different metrics. We will define a list of metrics that we want to use for evaluation. The metrics we want to use are:\n",
    "- Maximum Error\n",
    "- Mean Absolute Error\n",
    "- Regression Score\n",
    "- Mean Euclidean Distance\n",
    "\n",
    "**Instructions**   \n",
    "Define a list of metrics that we want to use for evaluation and add the required metrics to a list\n",
    "\n",
    "<details>\n",
    "  <summary>ðŸ’¡ Click to see a hint</summary>\n",
    "    HINT: The euclidean distance requires the columns it should be calculated on.                   \n",
    "\n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07980f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify metrics for evaluation\n",
    "metrics = [\n",
    "    # TODO: 4.1\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a53e30",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>ðŸ’¡ Click to see the solution</summary>\n",
    "\n",
    "```python\n",
    "metrics = [\n",
    "    MaxError(),\n",
    "    MeanAbsoluteError(),\n",
    "    MeanSquaredError(),\n",
    "    R2Score(),\n",
    "    MeanEuclideanDistance(\n",
    "        columns=[\n",
    "            \"/turtle1/pose/x_next\",\n",
    "            \"/turtle1/pose/y_next\",\n",
    "        ],\n",
    "    ),\n",
    "]\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de636b99",
   "metadata": {},
   "source": [
    "### Task 4.2 Create an Evaluation Loop\n",
    "\n",
    "We will now create an evaluation loop that will evaluate each trained model on the evaluation samples using the `evaluate_offline` strategy. We will store the evaluation reports in a dictionary.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "Implement the evaluation loop:\n",
    "   - call the evaluate_offline function and pass the required parameters\n",
    "   - store the reports in a dict for later comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e2f7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = {}\n",
    "for model_name, model in models.items():\n",
    "    logger.info(\"Evaluating model: %s\", model_name)\n",
    "\n",
    "    report = None # TODO 4.2\n",
    "    reports[model_name] = None # TODO : 4.2\n",
    "\n",
    "    print(report)\n",
    "    print_report_table(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2d3bd3",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>ðŸ’¡ Click to see the solution</summary>\n",
    "\n",
    "```python\n",
    "reports = {}\n",
    "for model_name, model in models.items():\n",
    "    logger.info(\"Evaluating model: %s\", model_name)\n",
    "    \n",
    "    report = evaluate_offline(\n",
    "        model=model,\n",
    "        environment=samples_eval,\n",
    "        metrics=metrics,\n",
    "        inputs=inputs,\n",
    "        outputs=outputs,\n",
    "    )\n",
    "    reports[model_name] = report\n",
    "\n",
    "    print(report)\n",
    "    print_report_table(report)\n",
    "\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13a8bb9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e674663",
   "metadata": {},
   "source": [
    "\n",
    "###  Task 4.3 Select a Model and Visualization  \n",
    "\n",
    "We want to select the best model based on the evaluation reports we created in the previous task. We will use the `select_best_model` function from the `flowcean.training` module to do this. We will also visualize the predictions of the best model against the ground truth using the `predictions_vs_ground_truth` function from the same module.\n",
    "\n",
    " **Instructions**\n",
    "\n",
    "   - call the `select_best_model` function and pass the required parameters\n",
    "   - we want to compare the mean euclidean distance\n",
    "   - call the `predictions_vs_ground_truth` function and pass the required parameters\n",
    "\n",
    "<details>\n",
    "  <summary>ðŸ’¡ Click to see a hint</summary>\n",
    " HINT: we can observe and collect samples   \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18cea52",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = None # TODO: 4.3\n",
    "\n",
    "logger.info(\"Best model: %s\", best_model_name)\n",
    "\n",
    "plot_predictions_vs_ground_truth(\n",
    "    # TODO: 4.3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdf6fc2",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>ðŸ’¡ Click to see a solution</summary>\n",
    "\n",
    "```python\n",
    "best_model_name = select_best_model(\n",
    "    reports,\n",
    "    output_name=\"multi_output\",\n",
    "    metric_name=\"MeanEuclideanDistance\",\n",
    ")\n",
    "\n",
    "logger.info(\"Best model: %s\", best_model_name)\n",
    "\n",
    "plot_predictions_vs_ground_truth(\n",
    "    samples_eval=samples_eval.observe().collect(),\n",
    "    input_names=inputs,\n",
    "    output_names=outputs,\n",
    "    models=models,\n",
    ")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1393f66b",
   "metadata": {},
   "source": [
    "## Section 5 : Final Task\n",
    "\n",
    "After you completed the tasks, just run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df699c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ‰ Congratulations! You finished the tutorial! ðŸŽ‰\n",
      "\n",
      "ðŸŽ‰ðŸ’«ðŸ’«ðŸ’«âœ¨ðŸŽŠðŸŽŠâœ¨ðŸŒŸðŸŒŸâœ¨ðŸŽ‰âœ¨âœ¨ðŸŒŸðŸ’«âœ¨ðŸŒŸðŸŽ‰ðŸŽ‰ðŸŽŠðŸŒŸðŸ’«ðŸŽŠðŸŽŠðŸ’«ðŸŽŠðŸŽŠðŸŽ‰ðŸ’«ðŸŽ‰ðŸŒŸðŸ’«ðŸ’«ðŸŒŸâœ¨âœ¨âœ¨ðŸ’«ðŸŽŠðŸŽŠâœ¨ðŸŽ‰ðŸŒŸðŸŽ‰ðŸŽŠðŸ’«ðŸ’«ðŸŒŸðŸ’«\n",
      "ðŸ’«ðŸŽŠðŸŽŠðŸŽŠðŸŒŸâœ¨ðŸŽŠâœ¨âœ¨ðŸŒŸâœ¨âœ¨ðŸŒŸðŸŒŸðŸŒŸðŸŽ‰ðŸŒŸðŸŒŸðŸ’«ðŸŒŸðŸ’«ðŸ’«âœ¨ðŸŒŸâœ¨ðŸ’«ðŸŽ‰âœ¨ðŸŒŸðŸŽ‰ðŸŒŸâœ¨ðŸ’«ðŸŽ‰ðŸŒŸðŸŽŠâœ¨ðŸŒŸðŸ’«ðŸ’«ðŸŽŠðŸŒŸðŸŽŠðŸŽ‰âœ¨ðŸ’«ðŸŽ‰ðŸŽŠðŸ’«ðŸ’«\n",
      "ðŸŽŠâœ¨ðŸŽ‰ðŸŽŠðŸŽŠðŸŽ‰ðŸ’«ðŸŽ‰ðŸ’«ðŸŽ‰ðŸŽŠðŸŽŠðŸŽ‰ðŸŽŠâœ¨ðŸŽ‰ðŸ’«âœ¨ðŸŒŸðŸŒŸðŸŽŠðŸŽ‰âœ¨ðŸŒŸðŸŽŠðŸŽŠðŸŽ‰ðŸŽ‰âœ¨ðŸ’«ðŸ’«âœ¨ðŸŽŠðŸŒŸðŸŽŠðŸŽ‰âœ¨ðŸŽ‰ðŸŽŠðŸŒŸðŸŽ‰ðŸ’«ðŸ’«ðŸŽ‰ðŸŒŸðŸŽ‰ðŸŽ‰ðŸŽ‰âœ¨ðŸŽŠ\n",
      "ðŸ’«ðŸŽŠðŸŽ‰ðŸŒŸðŸ’«ðŸ’«ðŸŒŸðŸŽ‰ðŸŒŸðŸŒŸâœ¨ðŸ’«ðŸŽŠðŸŒŸðŸŽ‰âœ¨ðŸ’«âœ¨âœ¨âœ¨ðŸŒŸðŸ’«ðŸŽ‰ðŸŽ‰ðŸŽŠâœ¨âœ¨ðŸŒŸðŸ’«ðŸŒŸðŸŽ‰âœ¨ðŸŒŸðŸŽŠðŸŽŠðŸŽŠðŸ’«âœ¨ðŸŒŸðŸŽ‰ðŸŒŸâœ¨ðŸŒŸðŸŒŸðŸŽŠðŸŽŠðŸŒŸðŸŽ‰ðŸ’«ðŸŒŸ\n",
      "ðŸŒŸðŸŽ‰ðŸŽ‰ðŸŒŸðŸŽŠðŸ’«âœ¨ðŸŽŠðŸ’«ðŸŒŸðŸŽŠðŸ’«âœ¨ðŸŽ‰ðŸŒŸðŸŽŠðŸŽ‰ðŸ’«ðŸ’«ðŸ’«ðŸŒŸâœ¨âœ¨ðŸŽ‰ðŸŽŠðŸ’«ðŸŽ‰ðŸŽŠðŸŽŠðŸŽŠðŸŽ‰ðŸŒŸâœ¨âœ¨ðŸŽŠâœ¨ðŸ’«ðŸŒŸðŸŒŸðŸŽŠðŸŒŸðŸŒŸðŸŽŠðŸ’«ðŸŽ‰âœ¨ðŸŒŸâœ¨ðŸ’«ðŸŽ‰\n",
      "ðŸŽ‰ðŸŽ‰âœ¨ðŸ’«ðŸŽŠðŸŽ‰ðŸŽŠðŸ’«ðŸŽ‰ðŸŒŸðŸŽ‰ðŸ’«ðŸŽŠðŸŽŠðŸ’«âœ¨ðŸŽ‰ðŸŒŸâœ¨ðŸŽ‰âœ¨âœ¨âœ¨ðŸŽŠðŸŒŸðŸŒŸðŸŒŸâœ¨âœ¨ðŸŒŸðŸŒŸðŸ’«ðŸŽŠâœ¨ðŸŒŸðŸŒŸðŸ’«ðŸ’«ðŸŒŸâœ¨ðŸŽŠâœ¨ðŸ’«ðŸŒŸðŸ’«ðŸŽŠðŸ’«ðŸŒŸðŸŽ‰ðŸŒŸ\n",
      "ðŸŒŸðŸŽŠðŸ’«ðŸŒŸðŸŽ‰ðŸŽ‰ðŸŽŠâœ¨ðŸŽŠðŸ’«ðŸŽ‰ðŸ’«ðŸ’«âœ¨ðŸŽ‰âœ¨ðŸŽ‰âœ¨ðŸŒŸâœ¨ðŸŒŸâœ¨ðŸ’«âœ¨âœ¨ðŸŒŸðŸŒŸðŸŽ‰ðŸŽ‰ðŸ’«âœ¨ðŸŒŸðŸŽ‰ðŸŒŸðŸŽŠðŸŽŠðŸŽ‰ðŸŽŠðŸŽŠðŸ’«ðŸŒŸâœ¨ðŸ’«ðŸŒŸðŸŽ‰ðŸŒŸðŸŒŸâœ¨ðŸŽŠâœ¨\n",
      "ðŸ’«ðŸŽŠðŸŽ‰âœ¨âœ¨ðŸŽŠðŸŒŸâœ¨ðŸŒŸðŸ’«ðŸŽ‰ðŸŒŸðŸŒŸðŸŒŸðŸŽŠðŸ’«ðŸ’«ðŸŽŠðŸ’«ðŸŽ‰ðŸŽŠâœ¨ðŸŽŠðŸ’«âœ¨ðŸ’«ðŸŒŸðŸ’«âœ¨âœ¨ðŸŽŠðŸŽ‰ðŸŽŠðŸŽŠðŸŽ‰âœ¨ðŸŽŠðŸŽ‰ðŸŽ‰ðŸŽŠðŸŽŠðŸŽ‰ðŸŽ‰âœ¨ðŸŽŠðŸŒŸðŸŽŠðŸŒŸðŸŽŠðŸ’«\n",
      "ðŸŒŸðŸŒŸâœ¨ðŸŒŸðŸ’«ðŸŒŸðŸŒŸðŸŽ‰âœ¨ðŸ’«âœ¨ðŸŒŸðŸŒŸðŸŽŠðŸ’«âœ¨ðŸŽ‰âœ¨ðŸŽŠðŸ’«ðŸŽŠðŸŽŠðŸŒŸðŸŽ‰ðŸŽ‰ðŸŽŠðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽŠðŸ’«ðŸ’«ðŸŽ‰ðŸ’«ðŸŒŸðŸ’«ðŸ’«ðŸŒŸðŸŒŸðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸ’«ðŸŽ‰âœ¨ðŸŒŸðŸ’«âœ¨ðŸŒŸðŸŽŠ\n",
      "ðŸŒŸðŸŽ‰ðŸ’«ðŸŒŸâœ¨ðŸŽ‰ðŸŒŸðŸŽŠðŸ’«ðŸŽŠâœ¨ðŸ’«ðŸ’«ðŸŽ‰ðŸŒŸâœ¨ðŸŽŠâœ¨ðŸ’«âœ¨âœ¨âœ¨âœ¨ðŸŽ‰âœ¨ðŸ’«ðŸ’«âœ¨âœ¨ðŸ’«âœ¨ðŸŽŠâœ¨ðŸŽ‰ðŸŽŠâœ¨ðŸ’«ðŸŒŸðŸŒŸðŸŽ‰ðŸŒŸâœ¨ðŸŽ‰âœ¨ðŸŽ‰âœ¨âœ¨ðŸŽŠðŸŽ‰ðŸŽ‰\n",
      "ðŸŽŠâœ¨ðŸŽŠðŸŒŸðŸŽ‰ðŸŒŸâœ¨ðŸ’«ðŸŒŸðŸŽŠðŸŒŸâœ¨ðŸŽŠðŸŽ‰ðŸ’«ðŸ’«ðŸŒŸðŸ’«ðŸŽŠðŸŒŸðŸŒŸðŸŽ‰âœ¨ðŸŒŸðŸŒŸðŸŽŠâœ¨âœ¨ðŸŽŠðŸŽ‰ðŸ’«âœ¨ðŸ’«âœ¨ðŸŽ‰âœ¨ðŸ’«ðŸŽ‰ðŸŽŠâœ¨ðŸŽŠðŸŽ‰ðŸ’«ðŸŽŠðŸŽ‰âœ¨ðŸŽŠðŸŽ‰âœ¨âœ¨\n",
      "ðŸŽ‰ðŸŽŠðŸ’«ðŸ’«ðŸŒŸðŸŒŸâœ¨âœ¨ðŸ’«ðŸ’«ðŸŽ‰ðŸŽŠðŸŒŸâœ¨ðŸŽŠâœ¨ðŸŒŸâœ¨ðŸŽ‰ðŸŽŠðŸŒŸðŸŽ‰âœ¨ðŸŽŠðŸ’«ðŸŽŠâœ¨ðŸŽŠðŸŽ‰ðŸŽŠðŸŽŠðŸŽ‰ðŸŽŠâœ¨ðŸ’«ðŸŽŠâœ¨âœ¨âœ¨ðŸŽ‰âœ¨ðŸ’«ðŸŽŠâœ¨âœ¨ðŸŽŠâœ¨ðŸŒŸðŸ’«ðŸŽ‰\n",
      "âœ¨âœ¨ðŸŒŸðŸŒŸâœ¨âœ¨ðŸŽ‰ðŸŽ‰ðŸŒŸðŸŽŠðŸŽŠðŸŽŠðŸ’«âœ¨ðŸŽ‰ðŸŽ‰âœ¨ðŸŒŸðŸŽŠðŸ’«ðŸŽŠðŸŒŸðŸŽŠâœ¨ðŸŽ‰ðŸ’«ðŸŽ‰ðŸŽŠðŸŒŸðŸŽ‰ðŸ’«ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŒŸâœ¨ðŸŽŠâœ¨ðŸŽ‰ðŸŽŠðŸŽ‰âœ¨ðŸŽŠðŸŽ‰ðŸ’«ðŸŽ‰ðŸŽŠðŸ’«ðŸŽ‰ðŸ’«\n",
      "âœ¨ðŸŽ‰âœ¨ðŸŒŸðŸŽŠâœ¨ðŸŒŸâœ¨âœ¨ðŸŒŸðŸŽŠðŸŽŠâœ¨ðŸŽŠðŸŽ‰âœ¨ðŸŽ‰ðŸŽ‰ðŸŽŠðŸŒŸðŸŽ‰âœ¨ðŸŒŸðŸŽ‰ðŸŒŸðŸ’«âœ¨ðŸŽŠðŸŽŠðŸ’«âœ¨ðŸŽŠâœ¨ðŸŒŸðŸŽŠðŸ’«ðŸŒŸðŸŽ‰âœ¨ðŸŽŠðŸŽŠðŸ’«ðŸ’«ðŸ’«ðŸŽ‰ðŸŽ‰ðŸŽŠðŸŒŸðŸŽŠðŸŽŠ\n",
      "ðŸŽ‰âœ¨ðŸŒŸâœ¨âœ¨ðŸŒŸðŸŽŠðŸŽ‰ðŸŽŠðŸŽŠðŸŽŠðŸ’«ðŸŽŠâœ¨ðŸ’«ðŸŽ‰ðŸ’«ðŸŒŸâœ¨ðŸ’«ðŸ’«ðŸŒŸðŸŒŸðŸŒŸðŸ’«ðŸŽŠðŸŒŸðŸŽŠâœ¨ðŸŽ‰ðŸŒŸðŸŽ‰ðŸŽŠðŸ’«ðŸŽ‰ðŸŽŠðŸ’«ðŸŒŸðŸ’«ðŸŽŠðŸŽ‰ðŸŽ‰ðŸ’«âœ¨ðŸŒŸâœ¨ðŸ’«ðŸŽŠâœ¨âœ¨\n",
      "\n",
      "ðŸŽ¯ Great job! Keep learning & experimenting! ðŸš€\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from _helper_functions import surprise\n",
    "\n",
    "surprise()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flowcean (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
